                    Background                  Back propagation NN BPNN          The back propagation NN BPNN is one of the most          commonly usedNN    and is the NNchosen for many          genetic epidemiology studies            In          this study we used a traditional fullyconnected          feedforwardnetwork comprised of one input layer zero          one or two hidden layersand one output layer trained          by back propagation The softwareused the NICO toolkit          was developed at the Royal Institute ofTechnology          httpwwwspeechkthseNICOindexhtml          Defining the network architecture is a very important          decisionthat can dramatically alter the results of the          analysis     There are a variety of          strategiesutilized for selection of the network          architecture The featuresof network architecture most          commonly optimized are the number of hiddenlayers and the          number of nodes in the hidden layer Many of          theseapproaches use a prediction error fitness measure          such that theyselect an architecture based on its          generalization to new observations     while others          use classification erroror training error     We          chose to useclassification error rather than prediction          error as a basis forevaluating and making changes to the          BPNN architecture because weuse prediction error to          measure the overall network fitness Webegan with a very          small network and varied several parameters includingthe          number of hidden layers number of nodes in the hidden          layerand learning momentum the fraction of the previous          change in aweight that is added to the next change to          obtain an appropriatearchitecture for each data set This          trialanderror approach iscommonly employed for          optimization of BPNN architecture                               A Genetic Programming Neural Network GPNN          Strategy          We developed a GPoptimized NN GPNN in an attempt to          improveupon the trialanderror process of choosing an          optimal architecturefor a pure feedforward BPNN The          GPNN optimizes the inputs froma larger pool of variables          the weights and the connectivity ofthe network including          the number of hidden layers and the numberof nodes in the          hidden layer Thus the algorithm attempts to          generateappropriate network architecture for a given data          set Optimizationof NN architecture using GP was first          proposed by Koza and Rice              The use of binary expression trees allow for the          flexibility ofthe GP to evolve a treelike structure that          adheres to the componentsof a NN Figure shows an          exampleof a binary expression tree representation of a NN          generated byGPNN Figure shows the sameNN that has been          reduced from the binary expression tree form tolook more          like a common feedforward NN The GP is constrained          insuch a way that it uses standard GP operators but          retains the typicalstructure of a feedforward NN A set          of rules is defined priorto network evolution to ensure          that the GP tree maintains a structurethat represents a          NN The rules used for this GPNN implementationare          consistent with those described by Koza and Rice              The flexibility of the GPNN allowsoptimal network          architectures to be generated that contain the          appropriate inputsconnections and weights for a given          data set          The GP has a set of parameters that must be          initialized beforebeginning the evolution of NN models          First a distinct set of inputsmust be identified All          possible variables can be included as optionalinputs          although the GP is not required to use all of them          Seconda set of mathematical functions used in weight          generation must bespecified In the present study we use          only the four basic arithmetic operatorsThird a fitness          function for the evaluation of GPNN models is definedby          the user Here we have designated classification error          as thefitness function Finally the operating parameters          of the GP mustbe initialized These include initial          population size number ofgenerations reproduction rate          crossover rate and mutation rate              Training the GPNN begins by generating an initial          random populationof solutions Each solution is a binary          expression tree representationof a NN similar to that          shown in Figure The GP then evaluates each NN The best          solutions areselected for crossover and reproduction          using a fitnessproportionateselection technique called          roulette wheel selection based on theclassification          error of the training data    A predefined          proportion of the best solutions will bedirectly copied          reproduced into the new generation Another          proportionof the solutions will be used for crossover          with other best solutionsCrossover must take place such          that the rules of network constructionstill apply Next          the new generation which is equal in size tothe original          population begins the cycle again This continuesuntil          some criterion is met at which point the GPNN stops          Thiscriterion is either a classification error of zero or          the maximumnumber of generations has been reached In          addition a bestsofarsolution is chosen after each          generation At the end of the GP runthe one          bestsofar solution is used as the solution to the          problem               While GPNN can be effective for searching highly          nonlinear multidimensionalsearch spaces it is still          susceptible to stalling on local minima     To          address this problem GPNN canbe run in parallel on          several different processors Several          isolatedpopulations or demes are created and a periodic          exchange of bestsolutions takes place between the          populations This is often referredto as an island          model     This exchangeincreases diversity among          the solutions in the different populationsFollowing the          set number of generations the bestsofar solutionsfrom          each of the           n processors are compared and a          singlebest solution is selected This solution has the          minimum classificationerror of all solutions generated                                       CrossValidation          While NN are known for their ability to model          nonlinear datathey are also susceptible to overfitting          To evaluate the generalizabilityof BPNN and GPNN models          we used  fold crossvalidation     CVHere the          data are divided into  parts of equal size We use          of the data to train the BPNN or the GPNN and we use          the remaining of data to test the model and estimate          the prediction error whichis how well the NN model is          able to predict disease status in that of the data          This is done  times each time leaving outa different           of data for testing     A prediction error is          estimated as an average across the           crossvalidationsCrossvalidation consistency is a          measure of the number of timeseach variable appears in          the BPNN or GPNN model across the  crossvalidations                That is we measuredthe consistency with          which each single nucleotide polymorphism SNPwas          identified across the  crossvalidations The          motivation forthis statistic is that the effects of the          functional SNPs shouldbe present in most splits of the          data Thus a high crossvalidationconsistency           lends support to that SNP being important forthe          epistasis model Further detail regarding the          implementationof crossvalidation can be found in the          Data Analysis section ofthe paper                            Results                  Trialanderror procedure for the back propagation          NN BPNN          The results of our trialanderror optimization          technique forselecting the traditional BPNN architecture          indicate the importanceof selecting the optimal NN          architecture for each different epistasismodel Table          shows the resultsfrom the traditional BPNN architecture          optimization technique onone data set from each epistasis          model generated with the two functionalSNPs only A          schematic for each of the best architectures selectedis          shown in Figure  Note thatthe optimal architecture          varied for each of the epistasis modelsFor example the          optimal architecture for Model  was composed of hidden          layers  nodes in the first layer and  nodes in          thesecond layer and a momentum of  In contrast for          Model  theoptimal architecture included  hidden layers           nodes in the firstlayer and  nodes in the second          layer and a momentum of  Differentarchitectures were          optimal for models   and  as well Similarresults          were obtained using the simulated data containing the          twofunctional and eight nonfunctional SNPs as well data          not shownThis provides further motivation for          automating the optimizationof the NN architecture in          order to avoid the uncertainty of          trialanderrorexperiments                          Modeling genegene interactions          Table summarizes the averageclassification error          ie training error and prediction errorie testing          error for the BPNN and GPNN evaluated using  datasets          for each of the five epistasis models with only the two          functionalSNPs in the analyses GPNN and the BPNN          performed similarly inboth training the NN and testing          the NN through crossvalidationIn each case the NN          solution had an error rate within  percentof the error          inherent in the data Due to the probabilistic natureof          the penetrance functions used to simulate the datathere          is some degree of noise simulated in the data The          average errorin the  datasets generated under each          epistasis model are     for Model              and  respectively Thereforethe error          estimates obtained by the BPNN or GPNN are very closeto          the true error rate There is also little opportunity for          either methodto overfit the data here since only the          functional SNPs are presentin the analysis These results          demonstrate that the BPNN and GPNNare both able to model          the nonlinear genegene interactions specifiedby these          models                          Detecting and modeling genegene          interactions          Table shows the average classificationerror and          prediction error for the BPNN and GPNN evaluated using          data sets for each of the five epistasis models with the          two functionaland eight nonfunctional SNPs GPNN          consistently had a lower predictionerror than the BPNN          while the BPNN consistently had a lower          classificationerror The lower classification error seen          with the BPNN is due tooverfitting These results show          that when nonfunctional SNPs arepresent the BPNN has a          tendency to overfit the data and thereforehave a higher          prediction error than GPNN GPNN is able to          modelgenegene interactions and develop NN models that          can generalizeto new observations          Table shows the power todetect the two functional          SNPs for GPNN and the BPNN using  datasets for each of          the five epistasis models with both the two functionaland          eight nonfunctional SNPs in the analyses For all five          modelsGPNN had a higher power than the BPNN to detect          both SNPs Theseresults demonstrate the high power of          GPNN in comparison to a BPNNwhen attempting to detect          genegene interactions in the presenceof nonfunctional          SNPs                            Discussion        We have implemented a NN that is optimized by GP using        the approachoutlined by Koza and Rice     Based on        theresults of the trial and error architecture        optimization wehave shown that the selection of optimal NN        architecture can alterthe results of data analyses For one        example data set from eachof the epistasis models the best        architecture was quite differentas shown in Table and        Figure for functional SNP only data This wasalso the case        for data containing functional and nonfunctionalSNPs data        not shown Since we only tried  different        architecturesthere may have been more appropriate        architectures for these datasets In fact since        enumeration of all possible NN architecturesis impossible            there is no wayto be certain that the global best        architecture is ever selectedThus the ability to optimize        the NN architecture using GPNN maydramatically improve the        results of NN analyses        Using simulated data we demonstrated that GPNN was able        to modelnonlinear interactions as well as a traditional        BPNN These resultsare important because it is well known        that traditional BPNN areuniversal function approximators           When given the functional SNPs one would expect the        BPNN to accuratelymodel the data Here we have shown that        GPNN is also capable ofaccurately modeling the data This        demonstrates that GPNN is ableto optimize the NN        architecture such that the NN evolved is ableto model data        as well as a BPNN        GPNN had improved power and predictive ability compared        to aBPNN when applied to data containing both functional        and nonfunctionalSNPs These results provide evidence that        GPNN is able to detectthe functional SNPs and model the        interactions for the epistasismodels described here with        minimal main effects in a sample size of cases and         controls In addition these are the two criteriawe        specified for considering GPNN an improvement over the        BPNNTherefore in situations where the functional SNPs are        known andthe user is attempting to model the data either        GPNN or a BPNN wouldbe equally useful However in        situations where the functional SNPsare unknown and the        user wants to perform variable selection aswell as model        fitting GPNN may be the preferable method This        distinctioncan be made due to the increase in power of GPNN        and the fact thatGPNN does not overfit the data much like        the traditional BPNN        We speculate that GPNN is not overfitting because while        theGPNN is theoretically able to build a tree with all of        the variablesas inputs it is not building a fully        connected NN This may bepreventing it from overfitting        the way that the BPNN has doneSecondly it is possible        that the strong signal of the correct solutionin the        simulated data caused the GP to quickly pick up that        signaland propagate trees with components of that model in        the populationBecause we have mutation set to  there is        never a large changeto the trees to lead them to explore in        the other areas of the searchspace As a result the GPNN        converges quickly on a small solutioninstead of exploring        the entire search space We plan to explorewhether GPNN        overfits in certain situations and if so to        developstrategies to deal with this issue such as the        threeway data split discussedby Roland            In an attempt to estimate the power of these NN methods        for arange of genetic effects we selected epistasis models        with varyingdegrees of heritability Heritability in the        broad sense is theproportion of total phenotypic variance        attributable to geneticfactors Thus higher heritability        values will have a stronger geneticeffect The five disease        models we used varied in heritability from to         To calculate the heritability of these models we usedthe        formula described by Culverhouse et al            Heritabilityvaries from  no genetic component to         completely geneticallyspecified        We selected models with varying heritability values to        obtaina more accurate comparison of the two NN methods in        the presenceof different genetic effects Interestingly        the results showedthat GPNN had greater than  power for        all heritability valuestested in the range of  to         In addition GPNN had power for all models with        a heritability of  or greaterHowever the BPNN had        greater than  power only for heritabilityvalues greater        than  Therefore the BPNN has low power todetect        genegene interactions that have an intermediate to        weakgenetic effect ie heritability value in the range        from to  while GPNN maintains greater than         power even foran epistasis model with a relatively weak        genetic effect ie  Thepower of GPNN falls below         for a heritability value that is verysmall ie         Thus GPNN is likely to have higher power thanthe        BPNN for detecting many genegene interaction models with        intermediateto small genetic effects        While GPNN has improved power and predictive ability        over theBPNN there are some advantages and disadvantages        to this approachAn advantage of GPNN is its modeling        flexibility With commercialBPNN software such as the BPNN        used here the user must definethe inputs the initial        values of the weights the number of connections eachinput        has and the number of hidden layers Often the        algorithmparameters that work well for one data set will        not be successfulwith another data set as demonstrated        here With the GP optimizationthe user only needs to        specify a pool of variables that the networkcan use and the        GP will select the optimal inputs weights connectionsand        hidden layers An important disadvantage of GPNN is the        requiredcomputational resources To use GPNN effectively        one needs accessto a parallel processing environment For a        BPNN on the other hand adesktop computer is the only        requirement Another disadvantage isthe interpretation of        the GPNN models The output of GPNN is a NNin the form of a        binary expression tree A NN in this form can bedifficult        to interpret as it can get quite large up to         nodes        While we have demonstrated the ability of GPNN to model        and detectgenegene interactions further work is needed to        fully evaluatethe approach For example we would like to        know whether using alocal search algorithm such as back        propagation or simulated annealing     to refine the        weights of a GPNN modelis useful This sort of approach has        been employed for a geneticalgorithm approach to optimizing        NN architecture for classificationof galaxies in astronomy            However as describedabove a local search could        lead to increased overfitting Nextthe current version of        GPNN uses only arithmetic operators in thebinary expression        trees The use of a richer function set includingBoolean        operators and other mathematical operators may allow        moreflexibility in the NN models Third we would like to        evaluate thepower of GPNN for a variety of high order        epistasis models suchas three four and five locus        interaction models Finally wewould like to develop and        distribute a GPNN software package                    Conclusions        The results of this study demonstrate that GP is an        excellentway of automating NN architecture design The NN        inputs weightsand interconnections are optimized for a        specific problem whiledecreasing susceptibility to        overfitting which is common in thetraditional BPNN        approach We have shown that GPNN is able to model        genegeneinteractions as well as a BPNN in data containing        only the functionalSNPs We have also shown that when there        are nonfunctional SNPsin the data ie potential false        positives GPNN has higher powerthan a BPNN in addition        to lower prediction error We anticipatethis will be an        important pattern recognition method in the searchfor        complex disease susceptibility genes                    Methods                  Data simulation          The goal of the data simulation was to generate data          sets thatexhibit genegene interactions for the purpose          of evaluating theclassification error prediction error          and power of GPNN and atraditional BPNN As discussed by          Templeton    epistasis or genegene interaction          occurs when the combined effectof two or more genes on a          phenotype could not have been predictedfrom their          independent effects Current statistical approaches          inhuman genetics focus primarily on detecting the main          effects and rarelyconsider the possibility of          interactions    In contrast we are interested in          simulating data using different epistasismodels that          exhibit minimal independent main effects but producean          association with disease primarily through interactions          We simulateddata with two functional single nucleotide          polymorphisms SNPsto compare GPNN to a BPNN for          modeling nonlinear epistasis modelsIn this study we use          penetrance functions as genetic models          Penetrance functions model the relationship between          genetic variationsand disease risk Penetrance is defined          as the probability of diseasegiven a particular          combination of genotypes We chose five epistasismodels          to simulate the data The first model used was          initiallydescribed by Li and Reich    and later by          Culverhouseet al    and Moore et al    Table          This model is based on the nonlinear XOR function that          generatesan interaction effect in which high risk of          disease is dependenton inheriting a heterozygous genotype                     Aa  from one SNPor a heterozygous          genotype from a second SNP            Bb  butnot both The highrisk          genotype combinations are           AaBB            Aabb            AABb and           aaBb with disease penetrance of           for all four Thesecond model was initially described by          Frankel and Schork    and later by Culverhouse et al             and Moore et al    Table In this model          high risk of disease is dependent on inheriting twoand          exactly two highrisk alleles either            a  or            b from two different loci For          this model the highrisk genotypecombinations are           AAbb            AaBb  and           aaBB withdisease penetrance of            and  respectively          The subsequent three models were chosen from a set of          epistasismodels described by Moore et al    Table             All five models were selected becausethey          exhibit interaction effects in the absence of any main          effectswhen allele frequencies are equal and genotypes          are generated usingthe HardyWeinberg equation In          addition we selected models withina range of          heritability values As mentioned previously          heritabilityin the broad sense is the proportion of          total phenotypic varianceattributable to genetic factors          Thus higher heritability valueswill have a stronger          genetic effect We selected models with          varyingheritability values to obtain a more accurate          comparison of thetwo NN methods in the presence of          varying genetic effects The heritabilitiesare              and  for Models    and           respectively Although the biological plausibility of          thesemodels is unknown they represent the worstcase          scenario for adiseasedetection method because they have          minimal main effectsIf a method works well with minimal          main effects presumably themethod will continue to work          well in the presence of main effects          Each data set consisted of  cases and  controls          each withtwo functional interacting SNPs SNPs generally          have two possiblealleles and in our study they were          simulated with equal allelefrequencies            p            q   We used a dummy          variableencoding for the genotypes where           n dummy variables areused for           n levels     We simulated          data sets of each epistasis model with two functional          SNPs Basedon the dummy coding these data would have          four variables and thusfour NN inputs Next we simulated           data sets of each model witheight nonfunctional SNPs          and two functional SNPs Based on the dummycoding these          data would have  variables and thus  NN inputsThese          two types of data sets allow us to evaluate the abilityto          either model genegene interactions or to detect          genegene interactions                          Data analysis          In the first stage of analysis we posed the following          questionIs GPNN able to model genegene interactions as          well or better thana traditional BPNN First we used a          fully connected feedforwardBPNN to model genegene          interactions in the simulated data containingfunctional          SNPs only The BPNN was trained for  epochs          Althoughthere are an effectively infinite number of          possible NN architecturesfor each data set we evaluated          the classification ability of different architectures          We chose the best architecture as the onethat minimized          the classification error and was most parsimoniousie          simplest network in the event of two or more with equal          classificationerror We began with a very small network           inputs  outputand varied the number of hidden          layers  number of nodesin the hidden layers                 and learning          momentum    We used this          optimizationprocedure to analyze  data sets of each          epistasis model We used fold crossvalidation to          evaluate the predictive ability of theBPNN models After          dividing the data into  equal parts the          architectureoptimization procedure is run on the first           of the data toselect the most appropriate          architecture Next the best architectureis used to test          the BPNN on the  of the data left out Thisis done           times each time leaving out a different  of thedata          for testing We then estimated the prediction error based          onthe average predictive ability across the           crossvalidations forall  data sets generated under          each epistasis model          Next we used the GPNN to analyze the same  data          sets foreach of the five epistasis models The GP          parameter settings included demes migration of best          models from each deme to all otherdemes every           generations each deme had a population size of           generations a crossover rate of  reproduction rate          of and mutation rate of  Fitness was defined as          classificationerror of the training data As with the          BPNN GPNN was requiredto use all four inputs in the NN          model for this stage of the analysisAgain we used           fold crossvalidation to evaluate the predictiveability          of the GPNN models We then estimated the prediction          errorof GPNN based on the average prediction error across          the  crossvalidationsfor all  data sets for each          epistasis model          The second aspect of this study involves answering the          followingquestion In the presence of nonfunctional SNPs          ie potentialfalsepositives is GPNN able to detect          genegene interactionsas well or better than a          traditional BPNN First we used a traditionalBPNN to          analyze the data with eight nonfunctional SNPs and          twofunctional SNPs We estimated the power of the BPNN to          detect the functionalSNPs as described below In this          network all possible inputs areused and the significance          of each input is calculated from its inputrelevance RI          where RI is the sum of squared weights for thei thinput          divided by the sum of squared weights for allinputs          Next we performed  permutations of the data to          determinewhat input relevance was required to consider a          SNP significantin the BPNN model The range of critical          relevance values for determiningsignificance was                      Next we calculated crossvalidation consistency                That is we measuredthe consistency with which          each SNP was identified across the crossvalidations          The basis for this statistic is that the functional          SNPseffect should be present in most splits of the data          Thus a highcrossvalidation consistency  lends          support to that SNP beingimportant for the epistasis          model Through permutation testingwe determined an          empirical cutoff for the crossvalidation consistencythat          would not be expected by chance We used this cutoff          valueto select the SNPs that were functional in the          epistasis model for eachdata set For the BPNN a          crossvalidation consistency greater thanor equal to five          was required to be statistically significant Weestimated          the power by calculating the percentage of datasets          wherethe correct functional SNPs were identified Either          one or bothof the dummy variables could be selected to          consider a locus presentin the model Finally we          estimated the prediction error based onthe average          predictive ability across  data sets for each          epistasismodel          Next we used the GPNN to analyze  data sets for          each of theepistasis models In this implementation GPNN          was not requiredto use all the variables as inputs Here          GPNN performed randomvariable selection in the initial          population of solutions Throughevolution GPNN selects          those variables that are most relevantWe calculated the          crossvalidation consistency as described above          Permutationtesting was used to determine an empirical          cutoff to select theSNPs that were functional in the          epistasis model for each data setFor the GPNN a          crossvalidation consistency greater than or equalto          seven was required to be statistically significant We          estimatedthe power of GPNN as the number of times the          functional SNPs wereidentified in the model divided by          the total number of runs Againeither one or both of the          dummy variables could be selected to considera locus          present in the model We also estimated the prediction          errorof GPNN based on the average prediction error across           data setsper epistasis model                            Authors contributions        JSP LWH and BCW performed the computer programming of        the softwareMDR participated in the design of the study        statistical analysesand writing of the manuscript JHM        participated in the design andcoordination of the study and        preparation of the final draft ofthe manuscript All        authors read and approved the final manuscript            