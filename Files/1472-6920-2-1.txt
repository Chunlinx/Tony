                    Background        Learning the skills of physical diagnosis is a critical        part of the medical school curriculum While there is        widespread agreement on what skills should be learned             there is little information on how well those skills        are learned especially among secondyear students        Measuring skill acquisition objectively is the essential        first step in improving clinical competence throughout        undergraduate and postgraduate training             During the past  years the objective structured        clinical evaluation or examination OSCE has become an        important method of assessing skills at all levels of        medical training      complementing traditional        evaluations of knowledge that use written multiple choice        questions and essay questions Compared with other levels        of training     little is known about the use of the        OSCE in physical diagnosis courses for secondyear medical        students        Several studies have used the OSCE to assess the effect        of educational interventions on specific skills at the        secondyear level such as historytaking for smoking            or examination of low back pain    or the breast             Others have examined the use of different        examination personnel as examiners or patients              compared students course feedback to their OSCE        performance     examined costs     or        reliability and generalizability     compared training        locations    or provided general descriptions of their        OSCEs         We found no studies that have        used the OSCE to report comprehensively on the spectrum of        skills learned in a secondyear physical diagnosis course        A comprehensive investigation is likely to help determine        what aspects of the educational process should be        improved        We used the OSCE to examine how well secondyear        students learned clinical skills in the secondyear        physical diagnosis course at Harvard Medical School We        were particularly interested which skills students        performed best and which were most difficult We assessed        what factors affected their performance on the overall        OSCE and on individual skills and stations Finally we        examined whether student OSCE scores varied from year to        year medical students performed differently from dental        students learning at different teaching sites affected        student performance and preceptors and examination        logistics affected student scores                    Methods                  Setting          This study took place at Harvard Medical School as          part of the required secondyear physical diagnosis          course PatientDoctor II     The course is taught          from September to May in the same general sequence at           clinical sites affiliated with the medical school Each          site is assigned  students for the entire hour          course including a total of  secondyear students from          Harvard School of Dental Medicine These dental students          are preparing for careers in consultative dentistry and          are required to learn the same clinical skills as Harvard          medical students The course involves a total of almost           faculty members One or two faculty members at each          site function as site directors and are intimately          involved in teaching the students and organizing other          faculty to teach in the course          Teaching sessions are organized by organ system          Students first learn skills by practicing on each other          and by taking histories and performing physical          examinations on selected patients Each year          approximately  medical students and  dental students          participate in the course Site directors meet monthly as          a group to determine the curriculum teaching techniques          and evaluation of the course                          Objective structured clinical examination          OSCE                      Development            We developed our OSCE primarily for educational            purposes to identify skills that each student has            learned well and those that need improvement during the            final portion of the course Performance on the OSCE is            not formally factored into a students grade for the            course but individual student OSCE scores are reviewed            by site directors            We designed the OSCE stations in  pilottested            them at evaluation sessions held in  and  and            reported on our results for      Following            established methods       the course director            and a committee of site directors and  thyear student            representatives developed case scenarios detailed            instructions and checklists consisting of questions or            tasks for  stations focused on specific clinical            areas From  we refined the content of the            stations and the OSCE organization through frequent            discussions with all site directors and through            feedback from students and OSCE preceptors We made no            changes to the exam during  Site directors            determined that all OSCE questions reflected essential            skills to be mastered by secondyear students We did            not weight OSCE questions stations or skills according            to degree of difficulty Annual feedback from students            and faculty endorsed the face validity of the OSCE In              of students and  of faculty agreed that            the OSCE represented an appropriate and fair evaluation            method and that enough time was given to complete the            stations            In the station OSCE nine different formats were            used alone or in combination question and answer            preceptor role play standardized patients actual            patients mechanical or structural models mm            slides audiotape videotape and CDROM Table             OSCE committee members designated each question or task            in the  stations as one of  clinical skills defined            as follows asking appropriate questions for the            history historytaking performing the physical            examination correctly physical examination technique            understanding the pathophysiology of physical findings            physical examination knowledge identifying            abnormalities on physical examination identification            of abnormalities developing appropriate differential            diagnoses for the clinical information obtained            differential diagnosis utilizing appropriate            patientdoctor interaction techniques patient            interaction and orally presenting the history and            differential diagnosis after taking a clinical history            patient presentation The total number of OSCE            questions each year was  and the mean number of            questions per skill was  range  evenly            distributed except for patient interaction and patient            presentation                                Implementation            Each year we held  sessions of the OSCE on  days            Monday Wednesday and Friday afternoons during a            oneweek period in April for all secondyear students            Two consecutive early and late afternoon sessions each            consisted of the same  stations and lasted  hours            To accommodate all students sessions were conducted            simultaneously on  floors of the medical schools            education center for a total of  OSCE sessions            Other than by date and time the sessions varied only            in the assignment of preceptors With the help of            guides timers and a strict schedule students rotated            through the  clinical stations each precepted by a            faculty member All preceptors received standardized            guidelines for checklists and feedback prior to each            OSCE session as did the standardized patients or            actors for the abdominal pain alcoholabdominal exam            knee and thyroid stations Fourteen stations were each             minutes in duration and two  abdominal pain and            headache  were  minutes in duration            At each station the student performed the indicated            tasks for twothirds of the time while the faculty            preceptor observed and checked off the tasks performed            correctly as defined by checklists one for each            student All tasks performed or questions answered by            each student were scored dichotomously as correct             or left blank  on the checklists During the final            onethird of time at each station the preceptor            provided feedback on the students performance as            advocated by others     Each year approximately             preceptors participated in the OSCE and  have            had experience with this OSCE and the checklists from            prior years                                    Data collection and analysis          Correct answers to all OSCE questions were recorded on          checklists by preceptors doubleentered by research          staff into an ASCII file and analyzed in SPSS              Total OSCE skill and station scores were calculated as          follows Each task or question counted one point and the          sum of tasks performed or questions answered correctly          for each station was designated the station score The          sum of station scores produced a total OSCE score for          each student Means of students scores  one standard          deviation for each of the  stations were computed To          compute the skills score each task or question on the          checklist for every station was designated as one of           skills The sum of tasks performed or questions answered          correctly for each skill produced a students skill          score Means of students scores for each of the  skills          were computed We combined the data from the            and  OSCEs          Total OSCE score scores for each clinical skill and          scores for each station were the primary outcome          variables In addition to the checklists completed by          faculty preceptors at each station for each student we          collected data on student preceptor and examination          variables to examine factors that might predict students          OSCE scores Student variables were type of student          medical or dental and teaching site Site AI The          preceptor variables were the floor first or third and          session group early or late afternoon assigned to each          OSCE preceptor Examination variables consisted of OSCE          year   or  the day each student took the          OSCE first second or third and sequence of          stations          For all predictor variables total OSCE skill and          station score means were compared with oneway ANOVA          Predictor variables significantly associated at p            with students total OSCE in univariate analysis were          entered into a linear regression model with the single          dependent variable being a students total OSCE score          The predictor variables were also entered into two          multivariate analysis of variance MANOVA models each          of which included multiple dependent variables As          dependent variables one model used clinical skill          scores and the second model used station scores          Separate models were used due to the high colinearity          between the skill and station scores since both of these          scores drew from the same item pool Pvalues within each          MANOVA model were adjusted for multiple comparisons In          addition we set the threshold for judging statistical          significance at p   to further reduce the          influence of multiple comparisons on p values          Because it was not logistically possible to obtain          interrater reliability due to the large number of          preceptors we used generalizability theory analysis              This analysis accounts statistically for rater error          by parsing out the variance relevant to the instrument in          question By modeling the variances as separate          characteristics we isolated the variance due to student          ability which in classical test theory is equivalent to          true score variance Other variances related to the test          are treated as error variances In this framework we          treated error due to differences in raters as error          variance          We calculated the KuderRichardson coefficient of          reliability KR for the total OSCE score clinical          skill and station scores The KR    is used for          binary items and is comparable to Cronbachs alpha This          measure of internal consistency is the best measure of          reliability when there are many more than two raters It          is equivalent to the generalizability or G coefficient          which examines total scale scores across raters in a          Dstudy scenario total scores are normally distributed          when the main effect variance due to raters is assumed to          be zero       In our study we assumed zero          maineffect variance to be the average across the large          pool of student raters because student assignment to a          preceptor for any given station was essentially          random                            Results        Over three years  secondyear students  medical        and  dental and  faculty participated in the OSCE for        secondyear physical diagnosis course Students answered        slightly more than half of all the OSCE items correctly           Figure a with almost no change over  years p          Individual student scores on the entire OSCE ranged        from  to         For clinical skills students scored highest on patient        interaction  followed by physical examination        technique  identification of abnormalities         historytaking  patient presentation  physical        examination knowledge  and differential diagnosis         p   Figure a Clinical skill scores        remained stable from  with only slight        improvement in historytaking  from  to  p                 For OSCE stations students scored highest on the        arthritis  ear  breast  and thyroid        stations  and lowest on the rectalprostate         mental status  hemoptysis  and calf pain        stations  p   Figure b We found        statistically significant yeartoyear differences among        the means for  of  stations However absolute        differences were small the largest differences were         for the skin and mental status stations data not        shown        When we examined the mean total clinical skill and        station scores according to student preceptor and        examination variables we found many statistically        significant associations in the univariate analyses        Multivariable analyses yielded fewer but still similarly        significant results Table presents the highest scoring        groups of predictor variables and the largest adjusted        differences between the highest scoring and the reference        groups        For adjusted total OSCE scores medical students scored         higher than dental students  vs  p          Table  No other variable was found to predict total OSCE        scores For adjusted clinical skill scores the largest        score differences were associated with the student variable         medical vs dental Medical students scores were         higher than dental students scores for patient        presentation and were slightly but significantly higher        for all other clinical skills except historytaking not        shown Table shows other significant differences among        several tested variables and groups but the absolute score        differences for these variables were relatively small         or less        Adjusted station scores demonstrated the largest        differences notably for teaching sites Table  For the        thyroid station the scores of students at site H were         higher than scores for students at reference site I Other        predictor variables accounted for smaller differences        Medical students adjusted scores on the rectalprostate        station were  higher than dental students scores They        were also significantly  but less than   higher for         other stations and no different for  stations not        shown Other variables  preceptor groups OSCE day and        OSCE year  also demonstrated some variation with the        largest differences being  among preceptor groups for        the knee station        Because teaching sites demonstrated the greatest        differences in OSCE station scores even after adjustment        for other variables we examined detailed intersite        differences Table  Eight adjusted station scores showed        substantial and significant differences in student scores        among teaching sites thyroid  knee  ear         arthritis  heart  mental status  lung         and skin  p   There were no        significant intersite differences for the breast        abdominal pain presentation headache alcoholabdominal        exam rectalprostate hemoptysis and calf pain stations        At every teaching site adjusted scores for  or  stations        were higher than at reference site I while scores for  to         other stations were lower than those for the reference        site        The overall reliability coefficient for the OSCE of         items was  Table  indicating good reliability of the        OSCE total score       The reliabilities of the        clinical skill scores ranged from  to  not shown        All but one of these scores  identification of        abnormalities   had a reliability coefficient of         or higher Reliabilities for clinical skill scores were        generally higher than for station scores which ranged from         to  Table                     Discussion        In an OSCE for a secondyear physical diagnosis course        we found a similar pattern of clinical skill acquisition        for three successive classes of students Students        performed better on interpersonal and technical skills         patient interaction historytaking physical examination        technique identification of abnormality and patient        presentation  than on interpretative or integrative skills         knowledge of the pathophysiology of physical examination        findings and differential diagnosis Teaching sites        differed widely from one another in performance on        individual OSCE stations only modestly on clinical skills        and not at all on total OSCE scores Medical students        scored somewhat better than dental students on the overall        OSCE all clinical skills except historytaking and almost        half of the stations        To our knowledge this study is the first to examine        comprehensively student performance for general clinical        skills and specific OSCE stations at the secondyear        student level Other studies of OSCEs for secondyear        students have focused on specific skills or content               or logistics and psychometrics       None        of the other studies employed multivariable analysis in        examining factors associated with OSCE performance By        including such analysis we were able to hold student and        examination variables constant in order to determine what        parts of the curriculum students mastered best and which        sites best taught specific physical diagnosis content        Higher scores on technical and patient interaction        skills compared to integrative skills are not surprising        Students at Harvard and in many medical schools begin to        practice some interviewing historytaking and patient        interaction during the first year curriculum and they        spend the entire secondyear physical diagnosis course        learning the techniques of physical examination        Investigators have reported similar results in other        settings OSCE scores among clinical clerks were higher on        historytakingphysical examination skills mean score         sd    and interviewing skills    and        lower on problem solving    skills     In a        nonOS CE examination using patient management problems        secondyear students scored    on history    on        physical examination and    on diagnosis            However in an OSCE for a secondyear neurology skills        course this pattern did not hold interpretative skill        scores    were higher than technical performance        scores    but no significance testing was reported                   Differential diagnosis has traditionally been considered        a secondary goal of our physical diagnosis course so        performance might be expected to be lower However        pathophysiology of disease is a major focus of the        secondyear curriculum Lower performance in knowledge of        the pathophysiology related to physical diagnosis compared        with technical performance of the physical examination        suggests that improvements integrating pathophysiology into        the teaching of the history and physical examination are        needed        Our other key finding was the variable performance by        students from different teaching sites on half the OSCE        stations despite similar performance by sites on the        overall OSCE Every site scored highest or nexttohighest        on at least one station and every site also scored lowest        or nexttolowest among sites on at least one station        Because of the large numbers of students in this study        even differences of  were statistically significant but        we consider differences greater than  to be        educationally significant and worthy of targeted        improvement efforts        We found the largest differences for the thyroid knee        ear arthritis heart lung mental status and skin        stations While students may have acquired overall physical        diagnosis skills similarly from site to site our results        suggest they did not learn equally at every site the skills        required for adequate examination or understanding of these        specific organ systems Intersite differences in        contentspecific station scores represent opportunities for        teaching sites to learn from one another using strategies        such as structured clinical instruction modules     or        reinforced practice    and developing more uniform        learning objectives and curriculum        Raw score results at one medical school must be        interpreted with caution since OSCEs at other schools may        differ in degree of difficulty The mean total OSCE score        of    in our study compares favorably with results        from one report on secondyear students               a report on clinical clerks        and a study        of thirdyear medicine students      but less        favorably with another report on secondyear students             None of these studies adjusted their student        scores        Consistent with a prior study from the UK     we        found that dental students scored lower than medical        students but not at a level which raises serious concerns        about their participation in the physical diagnosis course        While dental students scored lower on the majority of        stations they performed as well as medical students on        some stations with content that is not related to their        ultimate professional focus such as breast mental status        and abdominal pain        This study has several limitations We have not directly        assessed interrater reliability because of logistical and        cost constraints To address this methodological concern        we used generalizibility theory GT to produce a measure        of reliability similar in quality to interrater        reliability            There are a number of examples of the use of GT to        account statistically for rater error               Using GT can also overcome some problems inherent in        interrater reliability such as overestimating reliability            Due to the large number of preceptors involved in        our OSCE we made the statistically reasonable assumption        that any error due to rater differences is randomly        distributed Since randomly distributed error has a mean of        zero the error variance due to differences among all        preceptors is zero In our OSCE the variation of        individual raters around the mean station score of all        raters is very close to  eg  for the presentation        station data not shown and the standard deviations of        student scores are comparatively large eg  for the        presentation station Finally our GTbased assumption is        especially appropriate when the test scores used in the        analysis are created by summing many items across each        scale Summing in this fashion has the effect of further        randomizing the error variance The reliability or        internal consistency of the overall OSCE was good at         The reliability of  of  skill scores and  of  station        scores were acceptable at          Another benefit of the GT approach is that the        reliability coefficient derived from the GT analysis is        equivalent to Cronbachs alpha coefficient which for        binary items is equivalent to the KR reliability        coefficient The alpha coefficient is especially useful        during test development because it gives a measure of how        each item is contributing to the scale to which it has been        assigned This measure makes it easy to target items for        editing or deletion if they are not performing well Since        we are ultimately interested in using the scale scores for        our research study the GT measure of reliability is        appropriate for OSCEs involving many preceptors        The validity of our OSCE is only partially established        While several features support its face and content        validity construct and criterion validity remain to be        tested Multiple refinements of stations over the two        developmental years of the OSCE prior to this study yielded        broad agreement among the teaching site directors that all        OSCE questions reflected essential skills that should be        taught to and mastered by secondyear students Five        successive years of postOSCE student and faculty        evaluations have endorsed the OSCE as a highly appropriate        and acceptable method of education and evaluation Finally        a more recent investigation supports predictive validity of        our OSCE Physical diagnosis skills examined in the present        study correlated with scores on the USMLE Step  exam and        the skills that foreshadow the clinical clerkships         identification of abnormality and development of        differential diagnoses  best predicted USMLE scores                   Variation in skill scores may be due to different OSCE        station content Three of the skills drew their questions        from a smaller number of stations patient interaction         stations historytaking  stations presentation         station However patient interaction and historytaking        drew their questions from the same stations More        importantly the remaining  skills each drew their        questions from  stations For these  skills physical        examination technique physical examination knowledge        identification of abnormalities and differential        diagnosis the range of case content is considerable and        counters the concern that variation might be caused by case        content rather than by student performance        Variation in skill scores may be also due to inherent        differences in the degree of difficulty of exam questions        In our exam we did not weight OSCE questions according to        degree of difficulty We were not trying to create an exam        in which all items were of equal difficulty Instead we        created an OSCE in which the course directors considered        all test items essential to be mastered by the students        The results showed variation in the degree to which the        students mastered different clinical skills Remarkable        stability of overall scores over the three years of this        study with three different cohorts of students provides        evidence that there has been no significant teaching to        the OSCE This finding is consistent with a prior study of        fourthyear students            The successful implementation of the OSCE at our medical        school is relevant to all medical schools that face the        logistical challenges posed by multiple sites and        preceptors for student training in physical diagnosis        Furthermore the results from the secondyear OSCE reported        here and our prefourth year OSCE    have been useful        in helping to identify areas of weakness that could benefit        from remediation prior to the start of clinical clerkships        This benefit is especially true for students with the        lowest performance on individual stations and skills For        site directors and faculty the OSCE has also helped        identify those parts of the curriculum students had        difficulty mastering Holding a secondyear OSCE prior to        the end of a physical diagnosis course helps medical school        faculty identify opportunities for remediation focus the        remaining sessions of the course and improve future        physical diagnosis teaching                    Conclusions        Objective identification of skills acquired in a        physical diagnosis course is a necessary first step in        improving the quality of both the teaching and the learning        of those skills In our OSCE for a secondyear physical        diagnosis course students scored higher on interpersonal        and technical skills than on interpretive or integrative        skills Station scores identified specific content needing        improvements in students integrative and organ        systemspecific skills of physical diagnosis and in the        teaching of these skills                    Competing Interests        None declared            