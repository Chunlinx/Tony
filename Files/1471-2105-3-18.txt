                    Background        There are a growing number of RNA gene families and RNA        motifs      Many though not all RNAs conserve a        basepaired RNA secondary structure Computational analyses        of RNA sequence families are more powerful if they take        into account both primary sequence and secondary structure        consensus             Some excellent approaches have been developed for        database searching with RNA secondary structure consensus        patterns Exact and approximatematch pattern searches        analogous to PROSITE patterns for proteins have been        extended to allow patterns to specify longrange base        pairing constraints      In several cases specialized        programs have been developed to recognize specific RNA        structures     for example programs exist for        detecting transfer RNA genes       group I catalytic        introns     and small nucleolar RNAs      All        of these approaches though powerful lack generality and        they require expert knowledge about each particular RNA        family of interest        In primary sequence analysis the most useful analysis        techniques are general primary sequence alignment        algorithms with probabilistically based scoring systems         for example the BLAST     FASTA     or CLUSTALW           algorithms and the PAM    or BLOSUM           score matrices Unlike specialized programs a general        alignment algorithm can be applied to find homologs of any        query sequences Unlike pattern searches which give        yesno answers for whether a candidate sequence is a match        a scoring system gives a meaningful score that allows        ranking candidate hits by their statistical significance        It is of interest to develop general alignment algorithms        for RNA secondary structures        The problem I consider here is as follows I am given a        multiple alignment of an RNA sequence family for which I        know the consensus secondary structure I want to search a        sequence database for homologs that significantly match the        sequence         and structure of my query The        sequence analysis analogue is the use of profile hidden        Markov models profile HMMs to model multiple alignments        of conserved protein domains and to discover new        homologues in sequence databases      For instance        if we had an RNA structure equivalent of the HMMER profile        HMM program suite httphmmerwustleduit would be        possible to develop and efficiently maintain databases of        conserved RNA structures and multiple alignments analogous        to the Pfam or SMART databases of conserved protein domains                    Stochastic context free grammar SCFG algorithms        provide a general approach to RNA structure alignment              SCFGs allow the strong pairwise residue        correlations in nonpseudoknotted RNA secondary structure        to be taken into account in RNA alignments SCFGs can be        aligned to sequences using a dynamic programming algorithm        that guarantees finding a mathematically optimal solution        in polynomial time SCFG alignment algorithms can be        thought of as an extension of sequence alignment algorithms        particularly those with fully probabilistic hidden Markov        model formulations into an additional dimension necessary        to deal with D RNA secondary structure        While SCFGs provide a natural mathematical framework for        RNA secondary structure alignment problems SCFG algorithms        have high computational complexity that has impeded their        practical application Optimal SCFGbased structural        alignment of an RNA structure to a sequence costs         O          N  memory and         O          N  time for a sequence of length         N compared to         O          N  memory and time for sequence        alignment algorithms Corpet and Michot described a        program that implements a different general dynamic        programming algorithm for RNA alignment their algorithm        solves the same problem but even less efficiently        requiring         O          N  memory and         O          N  time     SCFGbased        alignments of small structural RNAs are feasible Using my        COVE software        httpwwwgeneticswustledueddysoftwarecove transfer        RNA alignments  nucleotides take about  cpu second        and  Mb of memory Most genome centers now use an        COVEbased search program tRNAscanSE for annotating        transfer RNA genes     However many larger RNAs of        interest are OUTSIDE the capabilities of the standard SCFG        alignment algorithm Alignment of a small subunit SSU        ribosomal RNA sequence to the SSU rRNA consensus structure        would take about  GB of RAM and an hour of CPU time        Applying SCFG methods to RNAs this large has required        clever heuristics such as using a precalculation of        confidently predicted regions of primary sequence alignment        to strongly constrain which parts of the SCFG dynamic        programming matrix need to be calculated     The steep        memory requirement remains a significant barrier to the        practicality of SCFG algorithms        Notredame         et al pointed specifically to this        problem     They described RAGA a program that uses a        genetic algorithm GA to optimize a pairwise RNA alignment        using an objective function that includes base pairing        terms Because GAs have an O         N  memory requirement RAGA can find        reasonable solutions for large RNA alignment problems        including ribosomal RNA alignments A different        memoryefficient approach has also been described             However both approaches are approximate and cannot        guarantee a mathematically optimal solution in contrast to        the mathematically optimal but more expensive dynamic        programming approaches        Here I introduce a dynamic programming solution to the        problem of structural alignment of large RNAs The central        idea is a divide and conquer strategy For linear sequence        alignment a divide and conquer algorithm was introduced by        Hirschberg     an algorithm known in the computational        biology community as the MyersMiller algorithm            Ironically at the time dynamic programming methods for        optimal sequence alignment were well known but were        considered impractical on s era computers because of        the extreme         O          N  memory requirement        MyersMiller reduces the memory complexity of a dynamic        programming sequence alignment algorithm from         O          N  to         O          N  at the cost of a roughly        twofold increase in CPU time Here I show that a divide        and conquer strategy can also be applied to the RNA        structural alignment problem greatly reducing the memory        requirement of SCFG alignments and making optimal        structural alignment of large RNAs possible        I will strictly be dealing with the problem of aligning        a target sequence of unknown secondary structure to a query        of known RNA structure By secondary structure I mean        nested nonpseudoknotted pairwise RNA secondary structure        interactions primarily WatsonCrick base pairs but also        permitting noncanonical base pairs This RNA structural        alignment problem is different from the problem of aligning        two known RNA secondary structures together     and        from the problem of aligning two RNA sequences of unknown        structure together under a secondary structureaware        scoring system                            Algorithm                  Prelude the simpler case of sequence          alignment          The essential concepts of a divide and conquer          alignment algorithm are most easily understood for the          case of linear sequence alignment               Dynamic programming DP algorithms for sequence          alignment fill in an           N            M DP matrix of scores           Fij for two sequences of lengths                    N and           M            N            M       Each score           Fij is the score of the optimal          alignment of prefix           x                       x                       i            of one sequence to prefix           y                       y                       j            of the other These scores are calculated          iteratively eg for global NeedlemanWunsch          alignment                    At the end           FN M contains the score of the          optimal alignment The alignment itself is recovered by          tracing the individual optimal steps backwards through          the matrix starting from cell            NM  The algorithm is           ONM in both time and memory          If we are only interested in the score not the          alignment itself the whole           F matrix does not have to be kept          in memory The iterative calculation only depends on the          current and previous row of the matrix Keeping two rows          in memory suffices in fact a compulsively efficient          implementation can get away with           N   cells A scoreonly          calculation can be done in           O            N  space          The fill stage of DP alignment algorithms may be run          either forwards and backwards We can just as easily          calculate the optimal score           Bi j of the best alignment of          the           suffix i             N of sequence  to the suffix           j             M of sequence  until one obtains          B the overall optimal score  the same number as           FNM           The sum of           Fij and           Bij at any cell in the optimal          path through the DP matrix is also the optimal overall          alignment score More generally           Fij  Bij at any cell            ij  is the score of the best          alignment that uses that cell Therefore since we know          the optimal alignment must pass through any given row           i somewhere we can pick some row           i in the middle of sequence           x run the forward calculation to           i to obtain row           Fi run the backwards calculation          back to           i to get row           Bi and then find argmax                       j                      F            i            j            B            i            j  Now I know the optimal          alignment passes through cell            ij  For clarity I am leaving          out details of how indels and local alignments are          handled          This divides the alignment into two smaller alignment          problems and these smaller problems can themselves be          subdivided by the same trick Thus the complete optimal          alignment can be found by a recursive series of split          point calculations Although this seems laborious  each          calculation is giving us only a single point in the          alignment  if we choose our split row           i to be in the middle the size of          the two smaller DP problems is decreased by about fold          at each split A complete alignment thus costs only about          times as much CPU time as doing the alignment in a single          DP matrix calculation but the algorithm is           O            N  in memory          A standard dynamic programming alignment algorithm for          SCFGs is the CockeYoungerKasami CYK algorithm which          finds an optimal parse tree eg alignment for a model          and a sequence        CYK is usually          described in the literature as a dynamic programming          recognition algorithm for nonstochastic CFGs in Chomsky          normal form rather than as a dynamic programming parsing          algorithm for SCFGs in any form The use of the name          CYK here is therefore a little imprecise     CYK          can be run in a memorysaving score only mode The DP          matrix for CYK can also be filled in two opposite          directions  either inside or outside analogous to          forward and backward DP matrix fills for linear sequence          alignment I will refer to these algorithms as CYKinside          and CYKoutside or just inside and outside but readers          familiar with SCFG algorithms should not confuse them          with the SCFG Inside and Outside algorithms              which sum over all possible parse trees rather than          finding one optimal parse tree I am always talking about          the CYK algorithm in this paper and by inside and          outside I am only referring generically to the          direction of the CYK DP calculation          The CYKinside and CYKoutside algorithms are not as          nicely symmetrical as the forward and backward DP fills          are in sequence alignment algorithms The splitting          procedure that one obtains does not generate identical          types of subproblems so the divide and conquer procedure          for SCFGbased RNA alignment is not as obvious                          Definition and construction of a covariance          model                      Definition of a stochastic context free            grammar            A stochastic context free grammar SCFG consists of            the following                         M different nonterminals here            called             states  I will use capital            letters to refer to specific nonterminals             V and             Y will be used to refer            generically to unspecified nonterminals                         K different terminal symbols            eg the observable alphabet acgu for RNA I will            use small letters             a b to refer generically to            terminal symbols             a number of             production rules of the form             V   where  can be any string            of nonterminal andor terminal symbols including as a            special case the empty string              Each production rule is associated with a            probability such that the sum of the production            probabilities for any given nonterminal             V is equal to                                 SCFG productions allowed in covariance            models            A covariance model is a specific repetitive profile            SCFG architecture consisting of groups of model states            that are associated with base pairs and singlestranded            positions in an RNA secondary structure consensus A            covariance model has seven types of states and            production rules Table             Each overall production probability is the            independent product of an emission probability             e                           v              and a transition probability             t                           v               both of which are positiondependent parameters            that depend on the state             v analogous to hidden Markov            models For example a particular pair P state             v produces two correlated letters                        a and             b eg one of  possible base            pairs with probability             e                           v                           a              b  and transits to one of            several possible new states             Y of various types with            probability             t                           v                           Y  A bifurcation B state            splits into two new start              S  states with probability             The E state is a special case  production that            terminates a derivation            A CM consists of many states of these seven basic            types each with its own emission and transition            probability distributions and its own set of states            that it can transition to Consensus base pairs will be            modeled by P states consensus single stranded residues            by L and R states insertions relative to the consensus            by more L and R states deletions relative to consensus            by D states and the branching topology of the RNA            secondary structure by B S and E states The            procedure for starting from an input multiple alignment            and determining how many states what types of states            and how they are interconnected by transition            probabilities is described next                                From consensus structural alignment to guide            tree            Figure shows an example input file a multiple            sequence alignment of homologous RNAs with a line            describing the consensus RNA secondary structure The            first step of building a CM is to produce a binary             guide tree of nodes representing            the consensus secondary structure The guide tree is a            parse tree for the consensus structure with nodes as            nonterminals and alignment columns as terminals            The guide tree has eight types of nodes Table                        These consensus node types correspond closely with a            CMs final state types Each node will eventually            contain one or more states The guide tree deals with            the consensus structure For individual sequences we            will need to deal with insertions and deletions with            respect to this consensus The guide tree is the            skeleton on which we will organize the CM For example            a MATP node will contain a Ptype state to model a            consensus base pair but it will also contain several            other states to model infrequent insertions and            deletions at or adjacent to this pair            The input alignment is first used to construct a            consensus secondary structure Figure  that defines            which aligned columns will be ignored as nonconsensus            and later modeled as insertions relative to the            consensus and which consensus alignment columns are            basepaired to each other Here I assume that both the            structural annotation and the labeling of insert versus            consensus columns is given in the input file as shown            in the line marked structure in the alignment in            Figure  Alternatively automatic methods might be            employed A consensus structure could be predicted from            comparative analysis of the alignment                  The consensus columns could be chosen as those columns            with less than a certain fraction of gap symbols or by            a maximum likelihood criterion as is done for profile            HMM construction                 Given the consensus structure consensus base pairs            are assigned to MATP nodes and consensus unpaired            columns are assigned to MATL or MATR nodes One ROOT            node is used at the head of the tree Multifurcation            loops andor multiple stems are dealt with by assigning            one or more BIF nodes that branch to subtrees starting            with BEGL or BEGR head nodes ROOT BEGL and BEGR            start nodes are labeled differently because they will            be expanded to different groups of states this has to            do with avoiding ambiguous parse trees for individual            sequences as described below Alignment columns that            are considered to be insertions relative to the            consensus structure are ignored at this stage            In general there will be more than one possible            guide tree for any given consensus structure Almost            all of this ambiguity is eliminated by three            conventions  MATL nodes are always used instead of            MATR nodes where possible for instance in hairpin            loops  in describing interior loops MATL nodes are            used before MATR nodes and  BIF nodes are only            invoked where necessary to explain branching secondary            structure stems as opposed to unnecessarily            bifurcating in single stranded sequence One source of            ambiguity remains In invoking a bifurcation to explain            alignment columns             ij by two substructures on            columns             ik and             k               j there will be more than one            possible choice of             k if             ij is a multifurcation loop            containing three or more stems The choice of             k impacts the performance of the            divide and conquer algorithm for optimal time            performance we will want bifurcations to split into            roughly equal sized alignment problems so I choose the                        k that makes             ik and             k               j as close to the same length as            possible            The result of this procedure is the guide tree The            nodes of the guide tree are numbered in preorder            traversal eg a recursion of number the current            node visit its left child visit its right child            thus parent nodes always have lower indices than their            children The guide tree corresponding to the input            multiple alignment in Figure is shown in Figure                                 From guide tree to covariance model            A CM must deal with insertions and deletions in            individual sequences relative to the consensus            structure For example for a consensus base pair            either partner may be deleted leaving a single unpaired            residue or the pair may be entirely deleted            additionally there may be inserted nonconsensus            residues between this pair and the next pair in the            stem Accordingly each node in the master tree is            expanded into one or more             states in the CM as follows            Table             Here we distinguish between consensus M for            match states and insert I states ML and IL for            example are both L type states with L type            productions but they will have slightly different            properties as described below            The states are grouped into a             split set of  states shown in            brackets above and an             insert set of  insert states            The split set includes the main consensus state which            by convention is first One and only one of the states            in the split set must be visited in every parse tree            and this fact will be exploited by the divide and            conquer algorithm The insert states are not            obligately visited and they have selftransitions so            they will be visited zero or more times in any given            parse tree            State transitions are then assigned as follows For            bifurcation nodes the B state makes obligate            transitions to the S states of the child BEGL and BEGR            nodes For other nodes each state in a split set has a            possible transition to every insert state in the             same node and to every state in            the split set of the             next node An IL state makes a            transition to itself to the IR state in the same node            if present and to every state in the split set of            the next node An IR state makes a transition to itself            and to every state in the split set of the next            node            This arrangement of transitions guarantees that            given the guide tree there is unambiguously one and            only one parse tree for any given individual structure            This is important The algorithm will find a maximum            likelihood parse tree for a given sequence and we wish            to interpret this result as a maximum likelihood            structure so there must be a one to one relationship            between parse trees and secondary structures                           The final CM is an array of             M states connected as a directed            graph by transitions             t                           v                           y  or probability  transitions                        v               yz  for bifurcations with the            states numbered such that              yz               v There are no cycles in the            directed graph other than cycles of length one eg            the selftransitions of the insert states We can            think of the CM as an array of states in which all            transition dependencies run in one direction we can do            an iterative dynamic programming calculation through            the model states starting with the last numbered end            state             M and ending in the root state             An example CM corresponding to the input alignment of            Figure  is shown in Figure             As a convenient side effect of the construction            procedure it is guaranteed that the transitions from            any state are to a             contiguous set of child states            so the transitions for state             v may be kept as an offset and a            count For example in Figure  state  an MP            connects to states      and  We can            store this as an offset of  to the first connected            state and a total count of  connected states We know            that the offset is the distance to the next nonsplit            state in the current node we also know that the count            is equal to the number of insert states in the current            node plus the number of split set states in the next            node These properties make establishing the            connectivity of the CM trivial Similarly all the            parents of any given state are also contiguously            numbered and can be determined analogously We are            also guaranteed that the states in a split set are            numbered contiguously This contiguity is exploited by            the divide and conquer implementation                                Parameterization            Using the guide tree and the final CM each            individual sequence in the input multiple alignment can            be converted unambiguously to a CM parse tree as shown            in Figure  Counts for observed state transitions and            singletpair emissions are then collected from these            parse trees The observed counts are converted to            transition and emission probabilities by standard            procedures I calculate maximum a posteriori            parameters using Dirichlet priors                                Comparison to profile HMMs            The relationship between an SCFG and a covariance            model is analogous to the relationship of hidden Markov            models HMMs and profile HMMs for modeling multiple            sequence alignments       A comparison may be            instructive to readers familiar with profile HMMs A            profile HMM is a repetitive HMM architecture that            associates each consensus column of a multiple            alignment with a single type of model node  a MATL            node in the above notation Each node contains a            match delete and insert HMM state  ML IL and            D states in the above notation The profile HMM also            has special begin and end states Profile HMMs could            therefore be thought of as a special case of CMs An            unstructured RNA multiple alignment would be modeled by            a guide tree of all MATL nodes and converted to an            unbifurcated CM that would essentially be identical to            a profile HMM The only difference is trivial the CM            root node includes a IR state whereas the start node            of a profile HMM does not All the other node types            especially MATP MATR and BIF and state types eg            MP MR IR and B are SCFG augmentations necessary to            extend profile HMMs to deal with RNA secondary            structure            The SCFG inside and outside algorithms are analogous            to the Forward and Backward algorithms for HMMs                 The CYKinside parsing algorithm is analogous to            the Viterbi HMM alignment algorithm run in the forward            direction CYKoutside is analogous to a Viterbi DP            algorithm run in the backwards direction                                    Divide and conquer algorithm                      Notation            I use             r v w y and             z as indices of states in the            model where             r               v              w              y               z These indices will range from                         M  for a CM             G that contains             M states refers to a subgraph of            the model rooted at state             r and ending at state             z for a contiguous set of states                        rz G             r  without a subscript refers            to a subgraph of the model rooted at state             r and ending at the highest            numbered E state descendant from state             r The complete model is  or             G  or just             G                         S                           v              refers to the             type of state             v  it will be one of seven types            DPLRSEB             C                           v              is a list of children for state             v eg the states that             v can transit to it will            contain up to six contiguous indices             y with             v              y              M              P                           v              is a list of parents for state             v states that could have            transited to state             v  it will contain up to six            contiguous indices             y with               y              v              P                           v              parent lists should not be confused with P state            types            I use             g h i j k p and             q as indices referring to            positions in a sequence             x where             g              h              p              q and             i              j for all subsequences of nonzero            length These indices range from              L for a sequence of length             L  Some algorithms will also use                        d to refer to a subsequence            length where             d              j              i   for a subsequence             x                           i                           x                           j                          The algorithms will have to account for subsequences            of zero length because of deletions By convention            these will be in the offdiagonal where             j              i   or             i              j   This special case usually            an initialization condition is the reason for the            qualification that             i              j for subsequences of             nonzero length            The CYKinside algorithm calculates a            threedimensional matrix of numbers                            v                           i              j  and CYKoutside calculates            numbers                            v                           i              j  I will refer to             v state indices as             deck coordinates in the            threedimensional matrices whereas             j and             i sequence positions are row            and column coordinates within each deck                            v              and                            v              refer to whole twodimensional decks containing            scores                            v                           i              j  and                            v                           i              j  for a particular state             v The dividing and conquering            will be done in the             v dimension by choosing            particular decks as split points                                The CYKinside algorithm            The CYKinside algorithm iteratively calculates                            v                           i              j   the log probability of the            most likely CM parse subtree rooted at state             v that generates subsequence             x                           i                           x                           j              of sequence             x The calculation initializes at            the smallest subgraphs and subsequences eg subgraphs            rooted at E states generating subsequences of length             and iterates outwards to progessively longer            subsequences and larger CM subgraphs            For example if were calculating                            v                           i              j  and             S                           v               P that is             v is a pair state             v will generate the pair             x                           i                           x                           j              and transit to a new state             y one of its possible            transitions             C                           v               which then will have to account for the smaller            subsequence             x                         i               x                         j   The log probability            for a particular choice of next state             y is the sum of three terms an            emission term log             e                           v                           x                           i                           x                           j               a transition term log             t                           v                           y  and an already calculated            solution for the smaller optimal parse tree rooted at             y                             y                           i               j   The answer for                            v                           i              j  is the maximum over all            possible choices of child states             y that             v can transit to            The algorithm INSIDE is as follows                        Input A CM subgraph and            subsequence             x                           g                           x                           q                                      Output Scoring matrix decks                            r                                         z                          INSIDErz gq                        for             v              z             down to             r                         for             j              g               to             q                         for             i              j               down to             g                         d              j              i                          if             S                           v               D or S                                       v                           i j                              y                           i j   log             t                           v                           y                         else if             S                           v               P and             d                                         v                           i j   log             e                           v                           x                           i                           x                           j                                           y                           i               j    log             t                           v                           y                         else if             S                           v               L and             d                                         v                           i j   log             e                           v                           x                           i                                           y                           i               j   log             t                           v                           y                         else if             S                           v               R and             d                                         v                           i j   log             e                           v                           x                           j                                           y                           i              j    log             t                           v                           y                         else if             S                           v               B                         y              z   left and right S children            of state             v                                        v                           i j                              y                           i k                              z                           k               j                         else if             S                           v               E and             d                                         v                           i              j    initializations                          else                                                    v                           i              j    initializations            Given a sequence             x of length             L and a CM             G of length             M  we could call INSIDE  M             L to align the whole model states              M  to the whole sequence              x                           x                           L               When INSIDE returns                            L  would contain the log            probability of the best parse of the complete sequence            with the complete model            We do not have to keep the entire             threedimensional matrix in memory to calculate these            scores As we reach higher decks                            v              in the three dimensional dynamic programming            matrix our calculations no longer depend on certain            lower decks A lower deck             y can be deallocated whenever all            the parent decks             P                           y              that depend on it have been calculated The            implementation goes even further and recycles decks            when possible saving some initialization steps and            many memory allocation calls for example since values            in all E decks are identical only one E deck needs to            be calculated and that precalculated deck can be reused            whenever             S                           v                           E             This deallocation rule has an important property            that the divide and conquer algorithm takes advantage            of when solving smaller subproblems for CM subgraphs            rooted at some state             w When the root state             w is an S state the  matrix            returned by INSIDE contains only one active deck                            w               No lower state              w can be reached from any state                         w without going through             w so all lower decks are            deallocated once deck             w is completed When the root            state             w is the first state in a split            set             wy see below for more            explanation all and only the decks                            w                                         y              are active when INSIDE returns            In some cases we want to recover the optimal parse            tree itself not just its score The INSIDE routine is            a modified version of INSIDE It keeps an additional            shadow matrix                            v                           ij  A                            v                           ij  traceback pointer either            records the index             y that maximized                            v                           ij  for state types DSPLR            or records the split point             k that maximized                            v                           ij  for a bifurcation B            state The  shadow matrix does not use the            deallocation rules  INSIDE can only be called for            problems small enough that they can be solved within            our available memory space Thus the INSIDE routine            works by calling INSIDE in a mode that also keeps a            shadow matrix  and then calls a recursive traceback            starting with             v i j                         Input A shadow matrix  for CM            subgraph             G             v rooted at state             v and subsequence             x                           i                           x                           j                                      Output An optimal parse tree             T             TRACEBACKvij                        if             S                           v                           E             attach             v                         else if             S                           v                           S or D            attach             v             TRACEBACK                           v                           i              j              i              j                         else if             S                           v               P            attach             x                           i                           v              x                           j                          TRACEBACK                           v                           i              j              i               j                          else if             S                           v               L            attach             x                           i                           v             TRACEBACK                           v                           i              j              i               j                         else if             S                           v               R            attach             v              x                           j                          TRACEBACK                           v                           i              j              i              j                          else if             S                           v               B                         y              z   left and right S children            of state             v             attach             v             TRACEBACK             y              i                             v                           i              j             TRACEBACK             z                             v                           i              j                j                                 The CYKoutside algorithm            The CYKoutside algorithm iteratively calculates                            v                           i              j  the log probability of the            most likely CM parse tree for a CM generating a            sequence             x                           x                           L                          excluding the optimal parse            subtree rooted at state             v that accounts for the            subsequence             x                           i                           x                           j               The calculation initializes with the entire            sequence excluded eg                            L    and iterates inward to            progressively shorter and shorter excluded subsequences            and smaller CM subgraphs            A complete implementation of the CYKoutside            algorithm requires first calculating the CYKinside            matrix  because it is needed to calculate                            v              when the parent of             v is a bifurcation                  However the divide and conquer algorithm described            here only calls OUTSIDE on             unbifurcated linear CM            subgraphs only the final state             z may be a B state there are no            internal bifurcations that lead to branches in the            model Thus the parent of a state             v is never a bifurcation and the            implementation can therefore be streamlined as            follows                        Input An unbifurcated CM subgraph            and subsequence             x                           g                           x                           q                                      Output Scoring matrix decks                            r                                         z                          OUTSIDErz gq                                       v                           i              j                  v              i              j                                        r                           g              q                           for             v              r               to             z                         for             j              q             down to             g                          for             i              g             to             j                          As with INSIDE we do not keep the entire  matrix            in memory A deck                            v              can be deallocated when all child decks             C                           v              that depend on the values in                            v              have been calculated This means that if the last            deck             z is a bifurcation or end state                                       z              will be the only active allocated deck when            OUTSIDE returns If             z is the last state in a split            set             wz all and only the split            set decks                            w                                         z              will be active when OUTSIDE returns                                Using CYKinside and CYKoutside to divide and            conquer            Now for any chosen state             v argmax                         i              j                             v                           i j                              v                           ij  tells us which cell             v i j the optimal parse tree            passes through conditional on using state             v in the parse We know that any            parse tree must include all the bifurcation and start            states of the CM so we know that the optimal alignment                        must use any chosen bifurcation            state             v and its child start states             w and             y Thus we are guaranteed that            when             S                           v               B and             C                           v                           w y                         is the optimal overall alignment score and we also            know that                        gives us a triplet that identifies three cells that            must be in the optimal alignment               v i j               w i k  and              y k               j  This splits the remaining            problem into three smaller subproblems  an alignment            of the sequence             x                           i                           x                           k              to a CM subgraph             wy   an alignment of the            sequence             x                         k               x                           j              to a CM subgraph             yM  and an alignment of the            twopiece sequence             x                           z                         i               x                         j               x                           L              to a CM subgraph              v             The subproblems are then themselves split and this            splitting can continue recursively until all the            bifurcation triplets on the optimal parse tree have            been determined            At this point the remaining alignment subproblems            might be small enough to be solved by straightforward            application of the standard CYKinside algorithm eg            INSIDE  However this is not guaranteed to be the            case A more general division strategy is needed that            does not depend on splitting at bifurcations            For the more general strategy we take advantage of            the fact that we know that the optimal parse tree must            also include one and only one state from the split set            of each node eg the noninsert states in the node            Let             wy be the indices of a split            set of states in the middle of the current model            subgraph              wy can be at most  states We            know that                        gives us a new cell              v i j  in the optimal parse            tree and splits the problem into two smaller problems            This strategy can be applied recursively all the way            down to single nodes if necessary We can therefore            guarantee that we will never need to carry out a full            CYKinside alignment algorithm on any subproblem The            most memoryintensive alignment problem that needs to            be solved is the very first split The properties of            the first split determine the memory complexity of the            algorithm            The bifurcationdependent strategy is a special case            of this more general splitting strategy where the B            state is the only member of its split set and where we            also take advantage of the fact that                            v                           i              j   max                           k                                         w                           i k                              y                           k               j  By carrying out the max                           k              operation during the split rather than before we            can split the current problem into three optimal pieces            instead of just two            If we look at the consequences of these splitting            strategies we see we will have to deal with three            types of problems Figure              A             generic problem means finding the            optimal alignment of a CM subgraph to a contiguous            subsequence             x                           g                           x                           q               The subgraph corresponds to a complete subtree            of the CMs guide tree  eg state             r is a start S and state             z is an end E may contain            bifurcations The problem is solved in one of two ways            If contains no bifurcations it is solved as a wedge            problem see below Else the problem is subdivided by            the bifurcationdependent strategy an optimal triple            i             k j  is found for a bifurcation            state             v and its children             w y splitting the problem into            a V problem and two generic problems             A             wedge problem means finding the            optimal alignment of an             unbifurcated CM subgraph to a            contiguous subsequence             x                           g                           x                           q               State             z does not have to be a start            state S it may be a state in a split set MP ML            MR or D State             z is an end E A wedge problem            is solved by the split setdependent strategy an            optimal              v i j  is found splitting the            problem into a V problem and a smaller wedge            problem             A             V problem consists of finding the            optimal alignment of an             unbifurcated CM subgraph to a            noncontiguous twopiece sequence             x                           g                           x                           h                           x                           p                           x                           g               exclusive of the residues             x                           h              and             x                           p              open circles in Figure  State             r can be a start state or any            state in a split set the same is true for             z A V problem is solved by a            split setdependent strategy an optimal              v i j  is found splitting the            problem into two V problems            The three recursive splitting algorithms to solve            these problems are as follows                                The genericsplitter routine                        Input A generic problem for CM            subgraph and subsequence             x                         g              q                          Output An optimal parse subtree             T             GENERICSPLITTERr z gq                        if no bifurcation in                         return WEDGESPLITTERrz gq                          else                                     v  lowest numbered bifurcation            state in subgraph                         wy  left and right S children            of             v                                        v               OUTSIDErw gq                                       w               INSIDEwy gq                                       y               INSIDEyz gq                                    T                VSPLITTERrv gi            jq                        T                GENERICSPLITTERwy            ik                        T                GENERICSPLITTERyz            klj            Attach S state             w of             T               as left child of B state             v in             T                           Attach S state             y of             T               as right child of B state             v in             T                                       return T                                               The wedgesplitter routine                        Input A wedge problem for            unbifurcated CM subgraph and subsequence             x                         g              q                          Output An optimal parse subtree             T             WEDGESPLITTERrz gq                         w              y   a split set chosen from            middle of                                       w                                         y                INSIDEwz gq                                       w                                         y                OUTSIDEry gq                                    T                VSPLITTERrv gi            jq                        T                WEDGESPLITTERvz            ij            Attach             T               to             T               by merging at state             v                         return T                                               The Vsplitter routine                        Input A V problem for            unbifurcated CM subgraph and twopart subsequence             x                         g              h               x                         p              q                          Output An optimal parse subtree             T             VSPLITTERrz gh pq                         wy   a split set chosen from            middle of                                       w                                         y                VINSIDEwz gh pq                                       w                                         y                VOUTSlDEry gh pq                                    T                VSPLITTERrv gi            jq                        T                VSPLITTERvz ih            pj            Attach             T               to             T               by merging at state             v                         return T                                               The vinside and voutside routines            The VINSIDE and VOUTSIDE routines are just INSIDE            and OUTSIDE modified to deal with a twopiece            subsequence             x                           g                           x                           h                           x                           p                           x                           g              instead of a contiguous sequence             x                           g                           x                           q               These modifications are fairly obvious The            range of             i j is restricted so that             i              h and             j              p Also VINSIDE w z g h p            q initializes                            z                           h              p    that is we know that            sequence             x                           h                           x                           p              has already been accounted for by a CM parse tree            rooted at             z                                 Implementation            In the description of the algorithms above some            technical detail has been omitted  in particular a            detailed description of efficient initialization steps            and details of how the the dynamic programming matrices            are laid out in memory These details are not necessary            for a high level understanding of the divide and            conquer algorithm However they may be necessary for            reproducing a working implementation Commented ANSIC            source code for a reference implementation is therefore            freely available at            httpwwwgeneticswustledueddyinfernalunder a GNU            General Public License This code has been tested on            GNULinux platforms            In this codebase the CM data structure is defined            in structsh The CM construction procedure is in            modelmaker cHandmodelmaker The guide tree is            constructed in HandModelmaker A CM is constructed            from the guide tree by cmfrommaster Individual            parse trees are constructed using the guide tree by            transmogrify The divide and conquer algorithm is            implemented in smallcyk cCYKDivideAndConquer which            will recursively call a set of functions the three            splitting routines GENERICSPLITTER            wedgesplitter and vsplitter the four alignment            engines INSIDE OUTSIDE VINSIDE and VOUTSIDE            and the two traceback routines INSIDET and            VINSIDET                                      Results and discussion                  Memory complexity analysis          The memory complexity of normal CYKinside is           O            N            M  for a model of           M states and a query sequence of           N residues since the full D          dynamic programming matrix is indexed           N            N            M and since           N            M  we can alternatively state the          upper bound as           O            N  The memory complexity of the          divide and conquer algorithm is           O            N log           M  The analysis that leads to          this conclusion is as follows          For a model with no bifurcations the divide and          conquer algorithm will never require more than  decks          in memory at once In the case of two adjacent MATP          nodes we will need six decks to store the scores for the          current node were calculating and four decks for the          split set of the adjacent node that were connecting to          and dependent upon Figure           Bifurcations will require some number of additional          decks for start states BEGLS and BEGRS to be kept In          INSIDE whenever we reach a deck for a start state we          will keep that deck in memory until we reach the parent          bifurcation state Half the time that will mean waiting          until another complete subgraph of the model is          calculated eg the subgraph rooted at the other start          child of that bifurcation that is to calculate deck                        v            for a bifurcation           v we need both decks                        w            and                        y            for its child start states           w and           y so we have to hold on to                        y            until we reach                        w             In turn the subgraph rooted at           w might contain bifurcations so          our calculation of                        w            might require additional decks to be kept Each          start deck we reach in the INSIDE iteration means holding          one extra deck in memory and each bifurcation we reach          means deallocating the two start decks it depends on          therefore we can iteratively calculate the maximum number          of extra decks we will require                    x                       M                                 for v            M            to                               return max                       v                      x                       v                      This number depends on the topology and order of          evaluation of the states in the CM Think of the          bifurcating structure of the CM as a binary tree numbered          in preorder traversal eg left children are visited          first and have lower indices than right children If          this is a complete balanced tree with           B bifurcations we will need log                      B extra decks If it is a maximally          unbalanced tree in which bifurcations only occur in left          children we will need           B extra decks all the right          children If it is a maximally unbalanced tree in which          bifurcations only occur in right children we will only          ever need  extra deck A leftunbalanced binary tree can          be converted to a rightunbalanced binary tree just by          swapping branches For a CM we cant swap branches          without affecting the order of the sequence thats          generated We can however get the same effect by          renumbering the CM states in a modified preorder          traversal Instead of always visiting the left subtree          first we visit the best subtree first where best          means the choice that will optimize memory usage This          reordering is readily calculated in           O            M  time not shown see cm          cCMRebalance in the implementation This way we can          never do worse than the balanced case and we will often          do better We never need more than log                      B extra decks Since           B            M we can guarantee a           O            N log           M  bound on memory complexity                          Time complexity analysis          The time complexity of the standard algorithm is           O            MN            BN  for a model of           M states            B of which are bifurcations          aligned to a sequence of           N residues Since           B            M and           M            N we can also state the upper          bound as           O            MN  or           O            N           The time complexity of the divide and conquer          algorithm depends on how close each split is to dividing          a problem into equal sized subproblems In the most ideal          case each call to GENERICSPLITTER could split into          three subproblems that each contained  of the states          and residues splitting those three subproblems would          only cost                       MN           in time eg only about  the time it took to          split the first problem Thus in an ideal case the time          requirement is almost completely dominated by the first          split and the extra time required to do the complete          divide and conquer algorithm could be negligible In          pathological cases optimal splits might lead to a series          of very unequally sized problems We never need to do          more splits than there are states in the model so we          cannot do worse than           O            M            N  in time          An example of a pathological case is an RNA structure          composed of a series of multifurcation loops such that          each bifurcation leads to a small stem on one side and          the rest of the structure on the other In such a case          every call to GENERICSPLITTER will split into a small          subproblem containing a small stem eg only removing a          constant number of states and residues per split and a          large subproblem containing all the remaining states and          sequence This case can be avoided It only arises          because of the decision to implement a simplified          CYKOutside algorithm and always split at the highest          bifurcations Better time performance could be guaranteed          if a complete CYKOutside algorithm were implemented at          the cost of complexity in the description and          implementation of the algorithm This would allow us to          choose a split point in a generic problem at any state in          the CM for instance in the middle regardless of its          bifurcating structure          In practice empirical results on a variety of real          RNAs see below indicate that the extra time required to          do the divide and conquer is a small constant factor A          more complex implementation does not seem to be          necessary                          Empirical results          Six structural RNA families were chosen for empirical          evaluations of the algorithm using available RNA          database resources  tRNA     S ribosomal RNA              signal recognition particle SRP RNA     RNase          P     small subunit SSU ribosomal RNA     and          large subunit LSU ribosomal RNA     For each          family a secondary structure annotated multiple          alignment of four or five example sequences was          extracted and used to construct a CM          The top of Table shows some statistics about these          alignments and CMs The number of consensus columns in          the alignments ranges from  tRNA to  LSU rRNA          about  are involved in consensus base pairs The          number of CM states is consistently about fold more          than the consensus alignment length ranging from           states tRNA to  LSU About  of the states in          each model are bifurcations After optimal reordering of          the model states the number of extra decks required by          the alignment algorithm is small ranging up to  for SSU          and  for LSU rRNA Therefore the minimum constant of           decks required in iterations across unbifurcated model          segments dominates the memory requirement The memory          required for extra decks does not have much impact even          for the largest structural RNAs Even without optimal          reordering the number of extra decks required for SSU          and LSU are only  and  respectively State reordering          was only needed to assure a           O            N log           M  memory complexity bound          To determine the memory and CPU time requirements for          a structural alignment one example sequence from each          family was aligned to the CM CPU time was measured and          memory requirements were calculated for three algorithms           the full CYKinside algorithm but in memorysaving          scoreonly mode eg INSIDEM L  the full          CYKinside algorithm with shadow matrix and traceback to          recover the optimal alignment eg INSIDE M L          and  the divide and conquer algorithm to recover an          optimal alignment eg GENERICSPLITTER M L The          most important comparison is between the full CYKinside          algorithm and the divide and conquer algorithm The          scoreonly CYKinside algorithm was included because a          complete CYK alignment couldnt be done on SSU and LSU          rRNA because of the steep memory requirement In all          cases where comparison could be done the scores and          alignments produced by these algorithms were verified to          be identical          The results of these tests are shown in the bottom          half of Table  The memory required by divide and          conquer alignment ranges up to  MB for LSU rRNA          compared to a prohibitive  GB for the standard CYK          algorithm The extra CPU time required by the divide and          conquer is small usually about  more with a maximum          of about twofold more for SRPRNA          The same results are plotted in Figure  Memory          requirements scale as expected           N for standard CYK alignment and          better than           N log           N for the divide and conquer          algorithm Empirical CPU time requirements scale          similarly for the two algorithms            N            N  The observed performance          is better than the theoretical worst case of           O            N  The proportion of extra time          required by divide and conquer is roughly constant over a          wide range of RNAs The difference shown in Figure is          exaggerated because times are plotted for scoreonly CYK          not complete CYK alignment in order to include CPU times          for SSU and LSU rRNA Because scoreonly CYK does not          keep a shadow traceback matrix nor perform the traceback          it is about  faster than CYK alignment as seen in the          data in Table                             Conclusions        The divide and conquer algorithm described here makes it        possible to align even the largest structural RNAs to        secondary structure consensus models without exceeding the        available memory on current computational hardware Optimal        SSU and LSU rRNA structural alignments can be performed in         MB and  MB of memory respectively Previous        structural alignment algorithms had to sacrifice        mathematical optimality to achieve ribosomal RNA        alignments        The CPU time requirement of the alignment algorithm is        still significant and even prohibitive for certain        important applications However CPU time is generally an        easier issue to deal with A variety of simple        parallelization strategies are possible Banded dynamic        programming algorithms eg calculating only relevant        parts of the matrix of various forms can also be explored        including not only heuristic schemes but also optimal        algorithms based on branch and bound ideas Properly        implemented banded DP algorithms would also save        additional memory        The algorithm takes advantage of the structure of        covariance models profile SCFGs splitting in the        dimension of the states of the model rather than in the        sequence dimensions The approach does not readily apply        therefore to unprofiled SCFG applications in RNA secondary        structure prediction        where the states are        fewer and more fully interconnected For these        applications it would seem to be necessary to divide and        conquer in the sequence dimensions to obtain any        significant improvement in memory requirements and it is        not immediately apparent how one would do this        The current implementation of the algorithm is not        biologically useful It is meant only as a testbed for the        algorithm It outputs a raw traceback structure and        alignment score not a standardly formatted alignment file        Most importantly the probability parameters for models are        calculated in a very quick and simple minded fashion and        are far from being reasonable for producing robustly        accurate structural alignments The next step along this        line is to produce good prior distributions for estimating        better parameters by estimating mixture Dirichlet priors        from known RNA structures     At this stage it would        not be meaningful to compare the biological alignment        accuracy of this implementation to for instance the        excellent performance of the RAGA genetic algorithm            A biologically useful implementation with accurate        alignment performance is of course the eventual goal of        this line of work but is not the point of the present        paper            