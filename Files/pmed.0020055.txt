                            Publishing results in traditional paper based way in a journal hides too much        information This is the verdict of Markus Ruschhaupt and colleagues who in a paper in         Statistical Applications in Genetics and Molecular Biology  article         discuss a paradigm for the presentation of complex datain this case from microarray        analyses The title of the article A Compendium to Ensure Reproducibility in        HighDimensional Classification Tasks may not lend itself easily to a clinical audience        but the underlying message to clinicians could not be more important that currently        studies involving large datasets especially ones that have a clinical outcome are so        poorly reported or possibly so poorly done that many are not reproducible This problem        was also the topic of a recent meeting in Heidelberg Best Practice in Microarray Studies        httpwwwbiometrieuniheidelbergdeworkshopsbestpracticeindexhtm        As microarrays have become mainstream research tools in biology and medicine the large        datasets and complex analyses from these studies have presented challenges for authors in        analyzing the data for reviewers and editors in deciding on the suitability of papers for        publication for journals in determining how much data needs to be presented within the        paper itself for other researchers in reproducing the data and finally for readers in        deciding how to assess the data presented The results from several highprofile papers        have already proved difficult to reproduce even by those with sufficient time and        computing expertise        Where do such analyses leave the new science of molecular pathology Ruschhaupt and        colleagues comment that the literature on the induction of prognostic profiles from        microarray studies is a methodological wasteland Much the same could be said of other        applications of molecular biology to clinical samples A systematic review of molecular and        biological tumor markers in neuroblastoma Clin Cancer Res   found that its        conclusions were limited by small sample sizes poor statistical reporting large        heterogeneity across studiesand publication bias John Ioannidis and colleagues Lancet          did a similar analysis of  microarray studies with major clinical        outcomes in cancer They showed that the studies were smallmedian sample size was         patients and validation was incomplete in most studies They recommended that molecular        prognostic studies be classified as phase  early exploratory probing associations phase         exploratory with extensive analyses or phase  large confirmatory studies with        prestated hypotheses and precise quantification of the magnitude of the effect and that        only studies that had undergone phase  testing should be considered robust enough for use        in clinical practice Most current studies should be considered as phase  or at best        phase         So despite considerable hype the published studies are far from the level of evidence        that would be accepted for virtually any other medical test In a review in         Hematology Am Soc Hematol Educ Program   Rita Braziel and colleagues        concluded rapid identification and neutralization of spurious results is essential to        prevent them from becoming accepted facts        But these problems are not new in medical research In  BMJ   Doug        Altman who was instrumental in developing the CONSORT guidelines for reporting of clinical        trials said that huge sums of money are spent annually on research that is seriously        flawed through the use of inappropriate designs unrepresentative samples small samples        incorrect methods of analysis and faulty interpretation and that quality control needs        to be built in from the start rather than the failures being discarded        So how can we ensure that the wealth of data pouring out of microarray and other        molecular diagnostic studies is turned into meaningful knowledge The Microarray Gene        Expression Data Society has proposed a set of guidelines MIAME for the reporting of        microarray data and that all such data should be deposited in public databases But as        Ruschhaupt and others have shown disclosure of results and data is not enough since there        is little consensus on the appropriate statistical analyses and many are developed on a        case by case basis which may not be reproducible even by the authors Some researchers        advocate the use of standard statistical packages which allows the reader to repeat an        entire analysis quickly and hence assess the robustness of the results Some authors have        produced a transcript of their statistical analyses as a supplement to their articles        eg Nucleic Acids Res  e At the very least authors should have a protocol with a        prespecified plan for patient selection and statistical analysisaccepted practice for        clinical trials but not yet for other medical research An ultimate aim for reporting        would be the type of compendium discussed by Ruschhaupt and colleaguesan interactive        document that bundles primary data statistical processing methods figures and derived        data together with the textual documentation and conclusions One such compendium is        illustrated in a paper by Robert Gentleman Stat Appl Genet Mol Biol  article          PLoS Medicine is keen to work with authors towards making such reporting        possible But although the time might have gone when the twodimensional journal article        could suffice for complex papers clinicians should nonetheless apply the same critical        assessment that they would for any other clinical tool If a result is too good to be true        it probably is            